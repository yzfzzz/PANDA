# 更新日志2022.11.27

## 超参数

使用mmdection官方推荐的超参数后，实验结果基本和原来的基本一样，训练过程中的损失函数等曲线也基本相同，故可以排除超参数的问题



## 数据预处理

暂未正式开始，不过阿里天池上有个top方案，只是用水平翻转、多尺度输入这两种而已



## 验证集、evaluation

在mmdection中，验证集评估的流程：

- 首先使用 对`single_img_test`函数对数据集进行推理
- 然后得出结果，写进一个列表results中。这个过程也就是test的过程
- 然后，将results和验证集标签注释的json文件比较，得出相应的指标

### 在线裁剪

但在之前的处理中，我们使用的是在线裁剪：

- 输入一张图片

- 在这张图片中随机裁剪一块3000*3000的图片

- 将这张图片输入到网络中训练

  在线裁剪如下图：

  ![image-20221127174359279](https://yzfzzz.oss-cn-shenzhen.aliyuncs.com/image/image-20221127174359279.png)

所以，实际上训练的时候，每一个epoch只训练了390（13个场景，每个场景30张千亿像素级照片）张经随机裁剪后的3000*3000的图片

但原来验证集json文件便无法发挥作用了，物体的位置被改变了，而`test_pipeline`又不能使用`dict(type='LoadAnnotations', with_bbox=True)`，所以就出现上周所说的不能使用验证集的问题

### 离线裁剪

故我首先对数据进行一个离线裁剪，并将裁剪后的图片、相应图片的json保存在文件夹中。然后，再进行训练。

![image-20221127180126548](https://yzfzzz.oss-cn-shenzhen.aliyuncs.com/image/image-20221127180126548.png)

新的训练流程如下：

![image-20221127180435637](https://yzfzzz.oss-cn-shenzhen.aliyuncs.com/image/image-20221127180435637.png)

这也是测试推理的过程，只不过最后的测试还需要将各个patch的预测结果，整合成一张图片的结果，最后提交官网

故，我们最后每一个epoch的照片，约有25000张3000*3000的图片

#### 因此，目前我使用了离线裁剪方案，划定验证集、训练集，然后使用了`IterBasedRunner`的方式训练，重新跑几个SOTA，看看验证集的评估指标怎么样
